<!doctype html>
<html lang="en-us">
  <head>
    <title>算法 // 川道</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.84.1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="川道" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://swpper.github.io/css/main.min.68e582a4d4ed824d6b7e3b5b37cae47eb3779bd631046379d0e68b38230cc3e2.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="算法"/>
<meta name="twitter:description" content="数据结构与算法 数据结构的常见操作  读取：查看索引处的值 查找：检查是否包含某个值，如果包含，给出索引 插入：插入一个新元素，包括移动其他数据的位置 删除：将索引处的数据去掉  时间复杂度：大O记法   大O记法不只是用固定的数字（如22、440）来表示算法的步数，而是基于要处理的数据量来描述算法所需的步数（步数与数据量的关系，通常考虑最坏情况）。或者说，大O解答的是这样的问题：当数据增长时，部署如何变化。
*O(N)*算法所需的步数等于数据量，意思是当数组增加一个元素时，*O(N)算法就要增加1步。而O(1)*算法无论面对多大的数组，其步数都不变。*O(N)*也称为线性时间，O(1)也称为常数时间，只要所需的步数是恒定的，都属于O(1)。
计算方法为：一共需要的步数（用数据量N表示） x 每步执行的操作数
  选择排序的时间复杂度也是$O(N^2)$，但是实际上(是$O(N^2/2)$)比冒泡排序快一倍，这是因为大O记法忽略常数，大O记法的作用可以说是比较算法的本质区别，量级区别。但是像选择排序和冒泡排序这种差别也不能忽视，因为实际应用中，肯定是要选择选择排序而不是冒泡排序。
  大O只保留最高的阶
  同时，大O记法只表明，对于不同的分类，存在一个临界点（大数据），在这一点后，一类算法会快于另一类，并永远保持下去，至于这个点在哪里，大O记法并不关心。因此，大O记法适用于比较不同大O分类下的算法，对于不同大O的分类，还需要进一步比较。
  时间复杂度一般考虑数据的最坏情况，但是有时候考虑大多数出现的情况（平均情况）是更有用的。因为现实世界中，最好情况和最坏情况很少发生。
  典型大O记法复杂度
  O(1)：表示算法无论面对多大的数据量，其步数总是相同的。例如数组末尾的插入与删除
  O(n)：描述一种处理N元素数组需花N步的算法的效率。如线性查找在普通数组上逐个检查每个格子，最坏情况下所需的步数。
  Olog(N)：表示处理N的元素需要$log_2N$步。对数时间。当数据量翻倍时，步数加1。例如二分查找（有序数组）。
  $O(N^2)$：二次时间
  冒泡排序：$O(N^2)$
  选择排序：$O(N^2/2)$
 选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中两个5的相对前后顺序就被破坏了，所以选择排序是一个不稳定的排序算法。    查入排序，优点是有提前退出机制
  将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。
从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）
  最好情况：$O(N)$；平均情况：$O(N^2/2)$；最坏情况：$O(N^2)$
      $O(N!"/>

    <meta property="og:title" content="算法" />
<meta property="og:description" content="数据结构与算法 数据结构的常见操作  读取：查看索引处的值 查找：检查是否包含某个值，如果包含，给出索引 插入：插入一个新元素，包括移动其他数据的位置 删除：将索引处的数据去掉  时间复杂度：大O记法   大O记法不只是用固定的数字（如22、440）来表示算法的步数，而是基于要处理的数据量来描述算法所需的步数（步数与数据量的关系，通常考虑最坏情况）。或者说，大O解答的是这样的问题：当数据增长时，部署如何变化。
*O(N)*算法所需的步数等于数据量，意思是当数组增加一个元素时，*O(N)算法就要增加1步。而O(1)*算法无论面对多大的数组，其步数都不变。*O(N)*也称为线性时间，O(1)也称为常数时间，只要所需的步数是恒定的，都属于O(1)。
计算方法为：一共需要的步数（用数据量N表示） x 每步执行的操作数
  选择排序的时间复杂度也是$O(N^2)$，但是实际上(是$O(N^2/2)$)比冒泡排序快一倍，这是因为大O记法忽略常数，大O记法的作用可以说是比较算法的本质区别，量级区别。但是像选择排序和冒泡排序这种差别也不能忽视，因为实际应用中，肯定是要选择选择排序而不是冒泡排序。
  大O只保留最高的阶
  同时，大O记法只表明，对于不同的分类，存在一个临界点（大数据），在这一点后，一类算法会快于另一类，并永远保持下去，至于这个点在哪里，大O记法并不关心。因此，大O记法适用于比较不同大O分类下的算法，对于不同大O的分类，还需要进一步比较。
  时间复杂度一般考虑数据的最坏情况，但是有时候考虑大多数出现的情况（平均情况）是更有用的。因为现实世界中，最好情况和最坏情况很少发生。
  典型大O记法复杂度
  O(1)：表示算法无论面对多大的数据量，其步数总是相同的。例如数组末尾的插入与删除
  O(n)：描述一种处理N元素数组需花N步的算法的效率。如线性查找在普通数组上逐个检查每个格子，最坏情况下所需的步数。
  Olog(N)：表示处理N的元素需要$log_2N$步。对数时间。当数据量翻倍时，步数加1。例如二分查找（有序数组）。
  $O(N^2)$：二次时间
  冒泡排序：$O(N^2)$
  选择排序：$O(N^2/2)$
 选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中两个5的相对前后顺序就被破坏了，所以选择排序是一个不稳定的排序算法。    查入排序，优点是有提前退出机制
  将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。
从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）
  最好情况：$O(N)$；平均情况：$O(N^2/2)$；最坏情况：$O(N^2)$
      $O(N!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://swpper.github.io/post/%E7%AE%97%E6%B3%95/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-09-22T09:45:41&#43;08:00" />
<meta property="article:modified_time" content="2022-09-22T09:45:41&#43;08:00" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://swpper.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="川道" /></a>
      <h1>川道</h1>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/">Home</a>
             - 
          
          <a class="app-header-menu-item" href="/tags/">Tags</a>
      </nav>
      <p>闻道千缘</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/swpper" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-link">
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
</svg></a>
        
          <a target="_blank" href="" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">算法</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Sep 22, 2022
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
              <a class="tag" href="https://swpper.github.io/tags/%E7%AE%97%E6%B3%95/">算法</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <h4 id="数据结构与算法">数据结构与算法</h4>
<h5 id="数据结构的常见操作">数据结构的常见操作</h5>
<ul>
<li>读取：查看索引处的值</li>
<li>查找：检查是否包含某个值，如果包含，给出索引</li>
<li>插入：插入一个新元素，包括移动其他数据的位置</li>
<li>删除：将索引处的数据去掉</li>
</ul>
<h5 id="时间复杂度大o记法">时间复杂度：大O记法</h5>
<ul>
<li>
<p><em>大O记法不只是用固定的数字（如22、440）来表示算法的步数，而是<strong>基于要处理的数据量</strong>来描述算法所需的步数（步数与数据量的关系，通常考虑最坏情况）。或者说，大O解答的是这样的问题：<strong>当数据增长时，部署如何变化</strong></em>。</p>
<p>*O(N)*算法所需的步数等于数据量，意思是当数组增加一个元素时，*O(N)<em>算法就要增加1步。而</em>O(1)*算法无论面对多大的数组，其步数都不变。*O(N)*也称为<strong>线性时间</strong>，<em>O(1)<em>也称为<strong>常数时间</strong>，只要所需的步数是恒定的，都属于</em>O(1)</em>。</p>
<p>计算方法为：一共需要的步数（用数据量N表示） x 每步执行的操作数</p>
</li>
<li>
<p>选择排序的时间复杂度也是$O(N^2)$，但是实际上(是$O(N^2/2)$)比冒泡排序快一倍，这是因为<strong>大O记法忽略常数</strong>，大O记法的作用可以说是比较算法的本质区别，量级区别。但是像选择排序和冒泡排序这种差别也不能忽视，因为实际应用中，肯定是要选择选择排序而不是冒泡排序。</p>
</li>
<li>
<p><strong>大O只保留最高的阶</strong></p>
</li>
<li>
<p>同时，大O记法只表明，对于不同的分类，存在一个临界点（大数据），在这一点后，一类算法会快于另一类，并永远保持下去，至于这个点在哪里，大O记法并不关心。因此，大O记法适用于比较不同大O分类下的算法，对于不同大O的分类，还需要进一步比较。</p>
</li>
<li>
<p>时间复杂度一般考虑数据的最坏情况，但是有时候考虑大多数出现的情况（平均情况）是更有用的。因为现实世界中，最好情况和最坏情况很少发生。</p>
</li>
<li>
<p>典型大O记法复杂度</p>
<ul>
<li>
<p><em>O(1)</em>：表示算法无论面对多大的数据量，其步数总是相同的。例如数组末尾的插入与删除</p>
</li>
<li>
<p><em>O(n)</em>：描述一种处理N元素数组需花N步的算法的效率。如线性查找在普通数组上逐个检查每个格子，最坏情况下所需的步数。</p>
</li>
<li>
<p><em>Olog(N)</em>：表示处理N的元素需要$log_2N$步。对数时间。当数据量翻倍时，步数加1。例如二分查找（有序数组）。</p>
</li>
<li>
<p>$O(N^2)$：二次时间</p>
<ul>
<li>
<p>冒泡排序：$O(N^2)$</p>
</li>
<li>
<p>选择排序：$O(N^2/2)$</p>
<ul>
<li>选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中两个5的<strong>相对前后顺序就被破坏了，所以选择排序是一个不稳定的排序算法</strong>。</li>
</ul>
</li>
<li>
<p>查入排序，优点是有提前退出机制</p>
<ul>
<li>
<p>将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。</p>
<p>从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）</p>
</li>
<li>
<p>最好情况：$O(N)$；平均情况：$O(N^2/2)$；最坏情况：$O(N^2)$</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>$O(N!)$：</p>
<ul>
<li>典型问题：旅行商问题：排列组合数N！
<ul>
<li>给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并回到起始城市的最短回路。它是<a href="https://baike.baidu.com/item/%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/3314860?fromModule=lemma_inlink">组合优化</a>中的一个<a href="https://baike.baidu.com/item/NP/7470332?fromModule=lemma_inlink">NP</a>难问题，在<a href="https://baike.baidu.com/item/%E8%BF%90%E7%AD%B9%E5%AD%A6/1559?fromModule=lemma_inlink">运筹学</a>和<a href="https://baike.baidu.com/item/%E7%90%86%E8%AE%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/11034581?fromModule=lemma_inlink">理论计算机科学</a>中非常重要。</li>
<li>由于该问题的可行解是所有顶点的全排列，随着顶点数的增加，会产生组合爆炸，它是一个NP完全问题。由于其在交通运输、电路板线路设计以及物流配送等领域内有着广泛的应用，国内外学者对其进行了大量的研究。早期的研究者使用精确算法求解该问题，常用的方法包括：<a href="https://baike.baidu.com/item/%E5%88%86%E6%9E%9D%E5%AE%9A%E7%95%8C?fromModule=lemma_inlink">分枝定界</a>法、<a href="https://baike.baidu.com/item/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92?fromModule=lemma_inlink">线性规划</a>法、<a href="https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92?fromModule=lemma_inlink">动态规划</a>法等。但是，随着问题规模的增大，精确算法将变得无能为力，因此，在后来的研究中，国内外学者重点使用近似算法或<a href="https://baike.baidu.com/item/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95?fromModule=lemma_inlink">启发式算法</a>，主要有<a href="https://baike.baidu.com/item/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95?fromModule=lemma_inlink">遗传算法</a>、<a href="https://baike.baidu.com/item/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E6%B3%95?fromModule=lemma_inlink">模拟退火法</a>、<a href="https://baike.baidu.com/item/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95?fromModule=lemma_inlink">蚁群算法</a>、<a href="https://baike.baidu.com/item/%E7%A6%81%E5%BF%8C%E6%90%9C%E7%B4%A2?fromModule=lemma_inlink">禁忌搜索</a>算法、<a href="https://baike.baidu.com/item/%E8%B4%AA%E5%A9%AA%E7%AE%97%E6%B3%95?fromModule=lemma_inlink">贪婪算法</a>和<a href="https://baike.baidu.com/item/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/16600562?fromModule=lemma_inlink">神经网络</a>等。</li>
</ul>
</li>
<li></li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="空间复杂度">空间复杂度</h5>
<ul>
<li>当内存有限制时，空间复杂度便会成为选择算法的一个重要参考因素。比如
<ul>
<li>给小内存的小型设备写程序</li>
<li>处理会迅速沾满内存的大数据</li>
</ul>
</li>
<li>大O记法
<ul>
<li>定义：当所处理的数据有N个元素时，该算法还需额外消耗多少元素大小的内存空间。（即处理时需要额外消耗的内存（辅助空间），如临时变量）</li>
<li>O(1)：不消耗额外的内存（消耗固定大小的内存？）</li>
<li>O(N)：消耗相同大小的内存</li>
<li></li>
<li></li>
</ul>
</li>
</ul>
<h5 id="其他">其他</h5>
<ul>
<li>综合比较一个算法的时间复杂度和空间复杂度</li>
<li>机器对内存的管理方式和编程语言的底层实现都会影响程序的性能，甚至会因为外部环境的变化使得之前高效的方法变得低效。</li>
<li>通过复杂度确定调优的方向，通过性能测试工具验证调优是否有效</li>
<li>许多看似复杂、深奥的事物，其实都是有简单概念构筑而成的，不理解有时可能是因为资料没解释清楚</li>
</ul>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
